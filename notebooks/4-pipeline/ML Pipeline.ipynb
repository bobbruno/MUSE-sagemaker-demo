{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will put together all the steps we built so far. It will execute the processing job and the generate the inference for the results in batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker as sm\n",
    "from datetime import datetime\n",
    "from time import strftime, gmtime\n",
    "\n",
    "bucket = sm.session.Session().default_bucket()\n",
    "smclient = boto3.client('sagemaker')\n",
    "s3client = boto3.client('s3')\n",
    "role = sm.get_execution_role()\n",
    "dask_repository_uri = '113147044314.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-dask-muse:latest'\n",
    "\n",
    "prefix = \"sagemaker/muse-dask-preprocess-demo\"\n",
    "input_prefix = prefix + \"/input/book-depository/raw\"\n",
    "code_prefix = prefix + \"/code\"\n",
    "input_preprocessed_prefix = prefix + \"/input/book-depository/preprocessed\"\n",
    "input_descriptions_prefix = prefix + \"/input/book-depository/descriptions\"\n",
    "input_rejected_prefix = prefix + \"/input/book-depository/rejected\"\n",
    "input_reports_prefix = prefix + \"/input/book-depository/reports\"\n",
    "\n",
    "output_inference_prefix = prefix + \"/output/book-depository/inference\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the Processing Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput,  ScriptProcessor\n",
    "\n",
    "dask_processor = ScriptProcessor(\n",
    "    base_job_name=\"dask-preprocessor\",\n",
    "    image_uri=dask_repository_uri,\n",
    "    command=[\"/opt/program/bootstrap.py\"],\n",
    "    role=role,\n",
    "    instance_count=10,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    max_runtime_in_seconds=1200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to execute muse-dask-processing-2020-07-07-01-09-02:\n",
      "\tScript location: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/code/preprocessing.py\n",
      "\tInputs: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/raw (10.00% sample)\n",
      "\tProcessed data destination: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/preprocessed/2020-07-07-01-09-02\n",
      "\tDescriptions data destination: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/descriptions/2020-07-07-01-09-02\n",
      "\tRejected data destination: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/rejected/2020-07-07-01-09-02\n",
      "\tReports destination: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/reports/2020-07-07-01-09-02\n"
     ]
    }
   ],
   "source": [
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "timestamp_prefix = '2020-07-07-01-09-02'\n",
    "\n",
    "job_name = f'muse-dask-processing-{timestamp_prefix}'\n",
    "s3_code_location = f\"s3://{bucket}/{code_prefix}/preprocessing.py\"\n",
    "sample_ratio = 0.1\n",
    "\n",
    "input_data = ProcessingInput(source=f\"s3://{bucket}/{input_prefix}\", destination='/opt/ml/processing/input', input_name='dataset')\n",
    "output_data = ProcessingOutput(source='/opt/ml/processing/processed/', destination=f\"s3://{bucket}/{input_preprocessed_prefix}/{timestamp_prefix}\", output_name='processed-dataset')\n",
    "descriptions_data = ProcessingOutput(source='/opt/ml/processing/descriptions/', destination=f\"s3://{bucket}/{input_descriptions_prefix}/{timestamp_prefix}\", output_name='descriptions-dataset')\n",
    "rejected_data = ProcessingOutput(source='/opt/ml/processing/rejected', destination=f\"s3://{bucket}/{input_rejected_prefix}/{timestamp_prefix}\", output_name='rejected-dataset')\n",
    "reports_on_data = ProcessingOutput(source='/opt/ml/processing/reports', destination=f\"s3://{bucket}/{input_reports_prefix}/{timestamp_prefix}\", output_name='dataset-reports')\n",
    "\n",
    "print(f\"Ready to execute {job_name}:\\n\\tScript location: {s3_code_location}\")\n",
    "print(f\"\\tInputs: {input_data.source} ({sample_ratio*100:0.2f}% sample)\")\n",
    "print(f\"\\tProcessed data destination: {output_data.destination}\")\n",
    "print(f\"\\tDescriptions data destination: {descriptions_data.destination}\")\n",
    "print(f\"\\tRejected data destination: {rejected_data.destination}\")\n",
    "print(f\"\\tReports destination: {reports_on_data.destination}\")      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  muse-dask-processing-2020-07-07-01-09-02\n",
      "Inputs:  [{'InputName': 'dataset', 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/raw', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'processed-dataset', 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/preprocessed/2020-07-07-01-09-02', 'LocalPath': '/opt/ml/processing/processed/', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'descriptions-dataset', 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/descriptions/2020-07-07-01-09-02', 'LocalPath': '/opt/ml/processing/descriptions/', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'rejected-dataset', 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/rejected/2020-07-07-01-09-02', 'LocalPath': '/opt/ml/processing/rejected', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'dataset-reports', 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/reports/2020-07-07-01-09-02', 'LocalPath': '/opt/ml/processing/reports', 'S3UploadMode': 'EndOfJob'}}]\n",
      "..........................\u001b[34mdistributed.scheduler - INFO - -----------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.76.15:42309'\u001b[0m\n",
      "\u001b[36mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.86.31:34251'\u001b[0m\n",
      "\u001b[32mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.101.24:43543'\u001b[0m\n",
      "\u001b[35mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.112.211:42123'\u001b[0m\n",
      "\u001b[33mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.118.179:44057'\u001b[0m\n",
      "\u001b[36mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.80.118:45493'\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Start worker at:    tcp://10.0.80.118:45393\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          Listening to:    tcp://10.0.80.118:45393\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          dashboard at:          10.0.80.118:43211\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -                Memory:                   15.17 GB\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-zdbmta06\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Start worker at:     tcp://10.0.76.15:41055\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          Listening to:     tcp://10.0.76.15:41055\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          dashboard at:           10.0.76.15:35687\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-b_b6txfs\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - -----------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Clear task state\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO -   Scheduler at:     tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO -   dashboard at:                     :8787\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.76.15:41055', name: tcp://10.0.76.15:41055, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.76.15:41055\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.118.179:34079', name: tcp://10.0.118.179:34079, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.118.179:34079\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.108.106:44729', name: tcp://10.0.108.106:44729, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.108.106:44729\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.91.195:44593', name: tcp://10.0.91.195:44593, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.91.195:44593\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.64.249:39233', name: tcp://10.0.64.249:39233, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.64.249:39233\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.71.116:39719', name: tcp://10.0.71.116:39719, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.71.116:39719\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.80.118:45393', name: tcp://10.0.80.118:45393, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.80.118:45393\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.112.211:39935', name: tcp://10.0.112.211:39935, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.112.211:39935\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.101.24:36543', name: tcp://10.0.101.24:36543, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.101.24:36543\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.86.31:46857', name: tcp://10.0.86.31:46857, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.86.31:46857\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Start worker at:     tcp://10.0.86.31:46857\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          Listening to:     tcp://10.0.86.31:46857\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          dashboard at:           10.0.86.31:40925\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -                Memory:                   15.00 GB\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-a9c65if7\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Start worker at:    tcp://10.0.101.24:36543\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          Listening to:    tcp://10.0.101.24:36543\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          dashboard at:          10.0.101.24:42159\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-hywkzt7j\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Start worker at:   tcp://10.0.112.211:39935\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          Listening to:   tcp://10.0.112.211:39935\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          dashboard at:         10.0.112.211:35959\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -                Memory:                   15.16 GB\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-emii2035\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[32mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.91.195:43435'\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Start worker at:    tcp://10.0.91.195:44593\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          Listening to:    tcp://10.0.91.195:44593\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          dashboard at:          10.0.91.195:36339\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-hn5r5oy1\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -       Start worker at:   tcp://10.0.118.179:34079\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -          Listening to:   tcp://10.0.118.179:34079\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -          dashboard at:         10.0.118.179:40689\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-_0pu8k1l\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[35mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.64.249:34935'\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Start worker at:    tcp://10.0.64.249:39233\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          Listening to:    tcp://10.0.64.249:39233\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          dashboard at:          10.0.64.249:35965\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -                Memory:                   14.98 GB\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-j3chx70u\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[35mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.108.106:33223'\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Start worker at:   tcp://10.0.108.106:44729\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          Listening to:   tcp://10.0.108.106:44729\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          dashboard at:         10.0.108.106:36435\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -                Memory:                   15.16 GB\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-t_humq0_\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.71.116:36791'\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Start worker at:    tcp://10.0.71.116:39719\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          Listening to:    tcp://10.0.71.116:39719\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          dashboard at:          10.0.71.116:45573\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - Waiting to connect to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-8iz2laaq\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -         Registered to:      tcp://10.0.76.15:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Receive client connection: Client-12177b07-bfef-11ea-8020-9e647da46e7a\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[34mSupported Languages: {'zh-tw', 'fr', 'ar', 'tr', 'th', 'ja', 'de', 'pt', 'zh', 'ko', 'nl', 'pl', 'es', 'it', 'ru', 'en'}\u001b[0m\n",
      "\u001b[34mLanguages ['ja', 'ar', 'ko', 'th'] will be dropped from the dataset\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mStarting processing\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mLoading data from /opt/ml/processing/input.\u001b[0m\n",
      "\u001b[34mTaking a fraction of 0.10 of the data\u001b[0m\n",
      "\u001b[34mRejected data will be sent to /opt/ml/processing/rejected.\u001b[0m\n",
      "\u001b[34mReports (if any) will be sent to /opt/ml/processing/reports.\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mGenerating reports...\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34m117460 records in total in the original dataset.\u001b[0m\n",
      "\u001b[34mNumber of books per language in the original dataset:\n",
      "      num_books\u001b[0m\n",
      "\u001b[34mlang           \u001b[0m\n",
      "\u001b[34men       108076\u001b[0m\n",
      "\u001b[34mde         4009\u001b[0m\n",
      "\u001b[34mes         2072\u001b[0m\n",
      "\u001b[34mfr         1178\u001b[0m\n",
      "\u001b[34mpl          826\u001b[0m\n",
      "\u001b[34mit          293\u001b[0m\n",
      "\u001b[34mru          155\u001b[0m\n",
      "\u001b[34mpt          138\u001b[0m\n",
      "\u001b[34mnl           73\u001b[0m\n",
      "\u001b[34mhi           56\u001b[0m\n",
      "\u001b[34mzh           52\u001b[0m\n",
      "\u001b[34mca           38\u001b[0m\n",
      "\u001b[34mcy           26\u001b[0m\n",
      "\u001b[34mar           26\u001b[0m\n",
      "\u001b[34mcs           24\u001b[0m\n",
      "\u001b[34maf           24\u001b[0m\n",
      "\u001b[34mda           21\u001b[0m\n",
      "\u001b[34mla           21\u001b[0m\n",
      "\u001b[34msv           20\u001b[0m\n",
      "\u001b[34mfi           17\u001b[0m\n",
      "\u001b[34mhe           15\u001b[0m\n",
      "\u001b[34mja           15\u001b[0m\n",
      "\u001b[34mvi           15\u001b[0m\n",
      "\u001b[34mfa           14\u001b[0m\n",
      "\u001b[34mel           14\u001b[0m\n",
      "\u001b[34mga           10\u001b[0m\n",
      "\u001b[34mtr           10\u001b[0m\n",
      "\u001b[34mgl            9\u001b[0m\n",
      "\u001b[34mno            9\u001b[0m\n",
      "\u001b[34mbn            8\u001b[0m\n",
      "\u001b[34mur            8\u001b[0m\n",
      "\u001b[34mta            8\u001b[0m\n",
      "\u001b[34msa            7\u001b[0m\n",
      "\u001b[34mmul           7\u001b[0m\n",
      "\u001b[34mmr            7\u001b[0m\n",
      "\u001b[34mml            6\u001b[0m\n",
      "\u001b[34mro            6\u001b[0m\n",
      "\u001b[34mms            6\u001b[0m\n",
      "\u001b[34mko            6\u001b[0m\n",
      "\u001b[34mzu            5\u001b[0m\n",
      "\u001b[34mkn            5\u001b[0m\n",
      "\u001b[34met            5\u001b[0m\n",
      "\u001b[34msi            5\u001b[0m\n",
      "\u001b[34mid            5\u001b[0m\n",
      "\u001b[34msr            5\u001b[0m\n",
      "\u001b[34mka            5\u001b[0m\n",
      "\u001b[34mth            4\u001b[0m\n",
      "\u001b[34meu            4\u001b[0m\n",
      "\u001b[34mtl            4\u001b[0m\n",
      "\u001b[34mku            3\u001b[0m\n",
      "\u001b[34mtk            3\u001b[0m\n",
      "\u001b[34mpa            3\u001b[0m\n",
      "\u001b[34msn            3\u001b[0m\n",
      "\u001b[34meo            3\u001b[0m\n",
      "\u001b[34mzxx           3\u001b[0m\n",
      "\u001b[34mst            3\u001b[0m\n",
      "\u001b[34mbe            2\u001b[0m\n",
      "\u001b[34muk            2\u001b[0m\n",
      "\u001b[34msl            2\u001b[0m\n",
      "\u001b[34mhr            2\u001b[0m\n",
      "\u001b[34mrn            2\u001b[0m\n",
      "\u001b[34mtg            2\u001b[0m\n",
      "\u001b[34mne            2\u001b[0m\n",
      "\u001b[34msd            2\u001b[0m\n",
      "\u001b[34mom            2\u001b[0m\n",
      "\u001b[34mhu            2\u001b[0m\n",
      "\u001b[34mrom           2\u001b[0m\n",
      "\u001b[34mgu            2\u001b[0m\n",
      "\u001b[34mis            2\u001b[0m\n",
      "\u001b[34mlv            2\u001b[0m\n",
      "\u001b[34mgd            2\u001b[0m\n",
      "\u001b[34mbs            2\u001b[0m\n",
      "\u001b[34mpi            2\u001b[0m\n",
      "\u001b[34mnso           1\u001b[0m\n",
      "\u001b[34mxh            1\u001b[0m\n",
      "\u001b[34myo            1\u001b[0m\n",
      "\u001b[34mjv            1\u001b[0m\n",
      "\u001b[34mbg            1\u001b[0m\n",
      "\u001b[34mff            1\u001b[0m\n",
      "\u001b[34mkm            1\u001b[0m\n",
      "\u001b[34mnds           1\u001b[0m\n",
      "\u001b[34mnn            1\u001b[0m\n",
      "\u001b[34mco            1\u001b[0m\n",
      "\u001b[34mrw            1\u001b[0m\n",
      "\u001b[34mhaw           1\u001b[0m\n",
      "\u001b[34mti            1\u001b[0m\n",
      "\u001b[34mtn            1\u001b[0m\n",
      "\u001b[34mam            1\u001b[0m\n",
      "\u001b[34msq            1\u001b[0m\n",
      "\u001b[34mnb            1\u001b[0m\n",
      "\u001b[34mts            1\u001b[0m\n",
      "\u001b[34mso            1\u001b[0m\n",
      "\u001b[34mmdr           1\u001b[0m\n",
      "\u001b[34mha            1\u001b[0m\n",
      "\u001b[34msyr           1\u001b[0m\n",
      "\u001b[34maus           1\u001b[0m\n",
      "\u001b[34mbo            1\u001b[0m\n",
      "\u001b[34mmi            1\u001b[0m\n",
      "\u001b[34mlt            1\u001b[0m\n",
      "\u001b[34megy           1\u001b[0m\n",
      "\u001b[34mpal           1\u001b[0m\n",
      "\u001b[34msco           1\u001b[0m\n",
      "\u001b[34mte            1\u001b[0m\n",
      "\u001b[34msm            1\u001b[0m\n",
      "\u001b[34mmis           1\u001b[0m\n",
      "\u001b[34mtt            1\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34m17852 descriptions were truncated at 1024 characters\u001b[0m\n",
      "\u001b[34mSaving transformed dataset to /opt/ml/processing/processed/\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mSaving descriptions to /opt/ml/processing/descriptions//dataset.jsonl\u001b[0m\n",
      "\u001b[34mDescriptions saved.\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mSaving rejected records...\u001b[0m\n",
      "\u001b[34m12379 records rejected because description is empty.\u001b[0m\n",
      "\u001b[34m116 records rejected because language is not supported.\u001b[0m\n",
      "\u001b[34m45 records rejected because language was filtered out.\u001b[0m\n",
      "\u001b[34m3749 records rejected because english was wrongly reported as language.\u001b[0m\n",
      "\u001b[34m5310 records rejected because description was too short.\u001b[0m\n",
      "\u001b[34m21599 records rejected in total.\u001b[0m\n",
      "\u001b[34mRejected records saved...\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mProcessing finished\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Remove client Client-12177b07-bfef-11ea-8020-9e647da46e7a\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Remove client Client-12177b07-bfef-11ea-8020-9e647da46e7a\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Close client connection: Client-12177b07-bfef-11ea-8020-9e647da46e7a\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[33mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[33mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[36mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[35mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[34mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[36mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[35mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\n",
      "CPU times: user 1.95 s, sys: 62.3 ms, total: 2.01 s\n",
      "Wall time: 7min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dask_processor.run(code=s3_code_location,\n",
    "                   inputs=[input_data],\n",
    "                   outputs=[output_data, descriptions_data, rejected_data, reports_on_data],\n",
    "                   job_name=job_name,\n",
    "                   arguments=['--sample', str(sample_ratio)]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Processing Job for Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reuse the base processing container and the output of the previous job to run inference. Here's the new script we'll need. It takes as input:\n",
    "- The location of the generated data\n",
    "- The desired destination of the inference results\n",
    "- The model artifact we should use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import boto3\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "def invoke_endpoint(row: pd.Series, region, endpoint):\n",
    "    runtime = boto3.client('runtime.sagemaker', region_name=region)\n",
    "    payload = row.description\n",
    "    response = runtime.invoke_endpoint(EndpointName=endpoint,\n",
    "                                       ContentType='text/csv',\n",
    "                                       Body=payload)\n",
    "    result = json.loads(response['Body'].read().decode())['output']\n",
    "    return(str(result))\n",
    "\n",
    "def invoke_inference(df, region, endpoint):\n",
    "    return(df.apply(invoke_endpoint, axis=1, region=region, endpoint=endpoint))\n",
    "\n",
    "def gen_inference(source_data_dir, inference_data_dir, endpoint_name, region, block_size='32MB', sample=1.0):\n",
    "    print(\"---------------------------------------------\")\n",
    "    print(f\"Loading data from {source_data_dir}.\")\n",
    "    if sample < 1.0:\n",
    "        print(f\"Taking a fraction of {sample:0.2f} of the data\")\n",
    "    print(\"---------------------------------------------\")\n",
    "    data = dd.read_csv(\n",
    "        f'{source_data_dir}/dataset-*.csv', header=0, \n",
    "        usecols=['description', 'title'],\n",
    "        blocksize=block_size,\n",
    "    ).repartition(partition_size=block_size).sample(frac=sample)\n",
    "    \n",
    "    data['embedding'] = data.map_partitions(\n",
    "        invoke_inference,\n",
    "        meta=pd.Series(name='embedding', dtype='U'),\n",
    "        region=region,\n",
    "        endpoint=endpoint_name\n",
    "    )\n",
    "    print(f\"Saving inference dataset to {inference_data_dir}\")\n",
    "    data.to_csv(f'{inference_data_dir}/dataset-*.csv', compute=True, index=False, quoting=csv.QUOTE_NONNUMERIC)    \n",
    "\n",
    "\n",
    "def start_dask_cluster(scheduler_ip):\n",
    "    # Start the Dask cluster client\n",
    "    try:\n",
    "        client = Client(\"tcp://{ip}:8786\".format(ip=scheduler_ip))\n",
    "        logging.info(\"Cluster information: {}\".format(client))\n",
    "    except Exception as err:\n",
    "        logging.exception(err)\n",
    "\n",
    "\n",
    "def parse_processing_job_config(config_file=\"/opt/ml/config/processingjobconfig.json\"):\n",
    "    with open(config_file, \"r\") as config_file:\n",
    "        config = json.load(config_file)\n",
    "    inputs = {in_path[\"InputName\"]: in_path[\"S3Input\"][\"LocalPath\"] for in_path in config[\"ProcessingInputs\"]}\n",
    "    outputs = {out_path[\"OutputName\"]: out_path[\"S3Output\"][\"LocalPath\"] for out_path in config[\"ProcessingOutputConfig\"][\"Outputs\"]}\n",
    "    return (inputs, outputs)\n",
    "    \n",
    "    \n",
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data-to-process\", type=str, default=\"dataset\")\n",
    "    parser.add_argument(\"--inference-data\", type=str, default=\"inference-dataset\")\n",
    "    parser.add_argument(\"--endpoint-name\", type=str, default=\"muse-large\")\n",
    "    parser.add_argument(\"--region\", type=str, default=\"us-east-1\")\n",
    "    parser.add_argument(\"--block-size\", type=str, default=\"32MB\")\n",
    "    parser.add_argument(\"--scheduler-ip\", type=str, default=sys.argv[-1])\n",
    "    parser.add_argument(\"--sample\", type=float, default=1.0)\n",
    "    args, _ = parser.parse_known_args()\n",
    "    \n",
    "    # Get processor scrip arguments\n",
    "    args_iter = iter(sys.argv[1:])\n",
    "    script_args = dict(zip(args_iter, args_iter))\n",
    "    return(args, script_args)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    inputs, outputs = parse_processing_job_config()\n",
    "    args, script_args = parse_arguments()\n",
    "    start_dask_cluster(args.scheduler_ip)\n",
    "    \n",
    "    print('----------------------------------------------------')\n",
    "    print('Starting inference')\n",
    "    print('----------------------------------------------------')\n",
    "    gen_inference(\n",
    "        source_data_dir=inputs[args.data_to_process], \n",
    "        inference_data_dir=outputs[args.inference_data],\n",
    "        endpoint_name=args.endpoint_name,\n",
    "        region=args.region,\n",
    "        block_size=args.block_size,\n",
    "        sample=args.sample\n",
    "    )\n",
    "    print('----------------------------------------------------')\n",
    "    print('Inference finished')\n",
    "    print('----------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelism = 10\n",
    "\n",
    "inference_processor = ScriptProcessor(\n",
    "    base_job_name=\"dask-inference\",\n",
    "    image_uri=dask_repository_uri,\n",
    "    command=[\"/opt/program/bootstrap.py\"],\n",
    "    role=role,\n",
    "    instance_count=parallelism-5,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    max_runtime_in_seconds=1200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_descr = smclient.describe_model(ModelName='model-muse-large-000002')\n",
    "model_name = model_descr['ModelName']\n",
    "model_data = model_descr['PrimaryContainer']['ModelDataUrl']\n",
    "model_image = model_descr['PrimaryContainer']['Image']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.model.Model(model_data = model_data,\n",
    "                       image=model_image,\n",
    "                       role=role, \n",
    "                       predictor_cls=sm.predictor.RealTimePredictor,\n",
    "                       name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using already existing model: model-muse-large-000002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "predictor = model.deploy(initial_instance_count=parallelism, instance_type='ml.c5.2xlarge', endpoint_name='muse-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to execute muse-dask-inference-2020-07-07-03-02-05:\n",
      "\tScript location: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/code/inference.py\n",
      "\tInputs: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/preprocessed/2020-07-07-01-09-02 (10.00% sample)\n",
      "\tInference data destination: s3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/output/book-depository/inference/2020-07-07-03-02-05\n"
     ]
    }
   ],
   "source": [
    "timestamp_prefix_2 = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "job_name = f'muse-dask-inference-{timestamp_prefix_2}'\n",
    "s3_code_location = f\"s3://{bucket}/{code_prefix}/inference.py\"\n",
    "s3client.upload_file(\"inference.py\", Bucket=bucket, Key=f\"{code_prefix}/inference.py\")\n",
    "sample_ratio = 0.1\n",
    "\n",
    "input_data = ProcessingInput(source=f\"s3://{bucket}/{input_preprocessed_prefix}/{timestamp_prefix}\", destination='/opt/ml/processing/input/', input_name='dataset')\n",
    "inference_data = ProcessingOutput(source='/opt/ml/processing/inference/', destination=f\"s3://{bucket}/{output_inference_prefix}/{timestamp_prefix_2}\", output_name='inference-dataset')\n",
    "\n",
    "print(f\"Ready to execute {job_name}:\\n\\tScript location: {s3_code_location}\")\n",
    "print(f\"\\tInputs: {input_data.source} ({sample_ratio*100:0.2f}% sample)\")\n",
    "print(f\"\\tInference data destination: {inference_data.destination}\")\n",
    "#print(f\"\\t Using endpoint: {predictor.endpoint}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the call to inference. Pay attention to the `region` parameter before execution - most labs are run under `us-east-1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  muse-dask-inference-2020-07-07-03-02-05\n",
      "Inputs:  [{'InputName': 'dataset', 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/input/book-depository/preprocessed/2020-07-07-01-09-02', 'LocalPath': '/opt/ml/processing/input/', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/code/inference.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'inference-dataset', 'S3Output': {'S3Uri': 's3://sagemaker-eu-west-1-113147044314/sagemaker/muse-dask-preprocess-demo/output/book-depository/inference/2020-07-07-03-02-05', 'LocalPath': '/opt/ml/processing/inference/', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................\u001b[33mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.114.100:42175'\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -       Start worker at:   tcp://10.0.114.100:45533\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -          Listening to:   tcp://10.0.114.100:45533\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -          dashboard at:         10.0.114.100:33477\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - Waiting to connect to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -                Memory:                   15.00 GB\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-x0princc\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO -         Registered to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[33mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[32mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.93.255:38945'\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Start worker at:    tcp://10.0.93.255:37835\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          Listening to:    tcp://10.0.93.255:37835\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -          dashboard at:          10.0.93.255:37481\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Waiting to connect to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -                Memory:                   14.98 GB\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-n6qmu45w\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO -         Registered to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[32mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - -----------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.109.91:35385'\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Start worker at:    tcp://10.0.109.91:38757\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          Listening to:    tcp://10.0.109.91:38757\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -          dashboard at:          10.0.109.91:33047\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - Waiting to connect to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-qr9xc43c\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.http.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - -----------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Clear task state\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO -   Scheduler at:    tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO -   dashboard at:                     :8787\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.109.91:38757', name: tcp://10.0.109.91:38757, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.109.91:38757\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO -         Registered to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[34mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.72.36:42149', name: tcp://10.0.72.36:42149, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.72.36:42149\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.114.100:45533', name: tcp://10.0.114.100:45533, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.114.100:45533\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.104.119:45641', name: tcp://10.0.104.119:45641, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.104.119:45641\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Register worker <Worker 'tcp://10.0.93.255:37835', name: tcp://10.0.93.255:37835, memory: 0, processing: 0>\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Starting worker compute stream, tcp://10.0.93.255:37835\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[35mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.104.119:40421'\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Start worker at:   tcp://10.0.104.119:45641\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          Listening to:   tcp://10.0.104.119:45641\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -          dashboard at:         10.0.104.119:42193\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Waiting to connect to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-9loaox2u\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO -         Registered to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[35mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[36mdistributed.nanny - INFO -         Start Nanny at: 'tcp://10.0.72.36:36655'\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Start worker at:     tcp://10.0.72.36:42149\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          Listening to:     tcp://10.0.72.36:42149\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -          dashboard at:           10.0.72.36:41143\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Waiting to connect to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -               Threads:                          4\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -                Memory:                   14.99 GB\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -       Local Directory: /dask-worker-space/dask-worker-space/worker-074oet0w\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO -         Registered to:     tcp://10.0.109.91:8786\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - -------------------------------------------------\u001b[0m\n",
      "\u001b[36mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Receive client connection: Client-c4cad664-bffe-11ea-8021-56ee4f9ff0a8\u001b[0m\n",
      "\u001b[34mdistributed.core - INFO - Starting established connection\u001b[0m\n",
      "\u001b[35mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[36mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mStarting inference\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mLoading data from /opt/ml/processing/input/.\u001b[0m\n",
      "\u001b[34mTaking a fraction of 0.10 of the data\u001b[0m\n",
      "\u001b[34m---------------------------------------------\u001b[0m\n",
      "\u001b[34mSaving inference dataset to /opt/ml/processing/inference/\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mInference finished\u001b[0m\n",
      "\u001b[34m----------------------------------------------------\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Remove client Client-c4cad664-bffe-11ea-8021-56ee4f9ff0a8\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Remove client Client-c4cad664-bffe-11ea-8021-56ee4f9ff0a8\u001b[0m\n",
      "\u001b[34mdistributed.scheduler - INFO - Close client connection: Client-c4cad664-bffe-11ea-8021-56ee4f9ff0a8\u001b[0m\n",
      "\u001b[33mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mdistributed.worker - INFO - Connection to scheduler broken.  Reconnecting...\u001b[0m\n",
      "\u001b[32mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[35mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[36mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\u001b[33mReceived a shutdown signal from Dask cluster\u001b[0m\n",
      "\n",
      "CPU times: user 1.79 s, sys: 62.7 ms, total: 1.85 s\n",
      "Wall time: 9min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "inference_processor.run(code=s3_code_location,\n",
    "                        inputs=[input_data],\n",
    "                        outputs=[inference_data],\n",
    "                        job_name=job_name,\n",
    "                        arguments=[\n",
    "                            '--sample', str(sample_ratio),\n",
    "                            '--endpoint-name', 'muse-large',\n",
    "                            '--region', 'eu-west-1'\n",
    "                        ]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the job finished correctly..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Completed'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_processor.jobs[-1].describe()['ProcessingJobStatus']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And download one of the resulting files to inspect it. The filename may need to be changed to `dataset-00.csv` if you ran with a large sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"/\".join(inference_data.destination.split(\"/\")[3:]) + '/dataset-0.csv'\n",
    "s3client.download_file(bucket, prefix, 'inference-sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file should be on your explorer window. You can open it with Jupyter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
